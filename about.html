<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>About | AI 101</title>
  <link rel="stylesheet" href="styles.css">
  <script src="https://unpkg.com/lucide@latest"></script>
</head>
<body>

  <nav class="nav">
    <div class="nav-inner">
      <a href="index.html" class="nav-brand">
        <span class="nav-badge">AI 101</span>
        <span class="nav-title">A Self-Paced Guide to AI in Medicine</span>
      </a>
      <button class="nav-toggle" aria-label="Toggle menu">
        <i data-lucide="menu"></i>
      </button>
      <div class="nav-links">
        <a href="index.html" class="nav-link">Topics</a>
        <a href="about.html" class="nav-link active">About</a>
        <a href="contribute.html" class="nav-link">Contribute</a>
        <div id="deployment-1fa153eb-d95d-460c-9711-c41a3f103961" class="nav-chatbot"></div>
      </div>
    </div>
  </nav>

  <main class="main">
    <article class="content">

      <header class="unit-header">
        <h1 class="unit-title">About This Guide</h1>
        <p class="unit-subtitle">
          Why AI literacy matters for clinicians and medical learners.
        </p>
      </header>

      <h2>The Problem We're Addressing</h2>
      <p>
        AI is entering healthcare faster than medical education is adapting.
        Clinicians encounter AI tools with little framework for evaluating
        them, supervising their outputs, or understanding their failure modes.
        The result is a dangerous gap: systems deployed without adequate
        oversight, clinicians unsure when to trust AI recommendations, and
        institutions struggling to govern technology they don't fully understand.
      </p>
      <p>
        This guide addresses that gap—not by making you into an AI
        engineer, but by developing the critical thinking skills needed to
        be a sophisticated consumer and supervisor of clinical AI.
      </p>

      <h2>Who This Is For</h2>
      <ul>
        <li>
          <strong>Clinicians in practice</strong> who encounter or will soon encounter
          AI tools in their clinical work and want to use them effectively
        </li>
        <li>
          <strong>Medical students and residents</strong> building foundational AI
          literacy as part of their training
        </li>
        <li>
          <strong>APP students</strong> (PA, NP, and other advanced practice programs)
          preparing for AI-augmented practice
        </li>
        <li>
          <strong>Anyone in healthcare</strong> who needs to evaluate AI systems,
          explain AI to patients, or think critically about these tools
        </li>
      </ul>
      <p>
        No technical background is required. We assume clinical knowledge and
        build AI literacy on that foundation.
      </p>

      <h2>Core Philosophy</h2>

      <div class="callout callout-principle">
        <div class="callout-title">Adaptive AI Practice</div>
        <p class="mb-0">
          The goal is not to master AI technology, but to become an
          <strong>adaptive practitioner</strong>—someone who can fluidly shift
          between integrating AI assistance and exercising independent
          clinical judgment, depending on the context.
        </p>
      </div>

      <p>
        We draw a distinction between <strong>Centaur</strong> and <strong>Cyborg</strong>
        modes of human-AI collaboration. Centaurs maintain clear division of
        labor; Cyborgs integrate more seamlessly. Both have their place. The
        adaptive practitioner knows when each mode is appropriate and can
        shift between them deliberately.
      </p>

      <h2>How This Guide Works</h2>

      <h3>Self-Paced Learning</h3>
      <p>
        Work through the modules at your own speed. There are no deadlines,
        no synchronous sessions, no cohort to keep up with. Spend more time on
        topics that interest you; skim what you already know.
      </p>

      <h3>Suggested Sequence</h3>
      <p>
        The modules are ordered to build on each other: foundations first
        (how AI systems work and fail), then generative AI (large language models
        and their supervision), then governance (liability, institutional policy,
        patient communication). But feel free to jump around based on your needs.
      </p>

      <h3>Primary Sources</h3>
      <p>
        We prioritize original research over textbooks. You'll read the
        actual Obermeyer paper on algorithmic bias, the CLAIM Checklist, the
        Med-PaLM publications—not summaries of summaries. This develops the
        skill of engaging directly with research evidence.
      </p>

      <h3>Hands-On Activities</h3>
      <p>
        Most modules include practical exercises: using NotebookLM, evaluating
        AI papers, crafting prompts. The goal is to apply concepts immediately,
        not just read about them.
      </p>

      <h2>What This Guide Is Not</h2>
      <ul>
        <li>
          <strong>Not a technical AI course.</strong> We don't teach you to
          build machine learning models. We teach you to evaluate, supervise,
          and work with them.
        </li>
        <li>
          <strong>Not a comprehensive survey.</strong> We don't cover every
          AI application in healthcare. We focus on core concepts that transfer
          across domains.
        </li>
        <li>
          <strong>Not a vendor certification.</strong> We're not training you
          to use specific products. We're developing judgment that applies to
          any AI system you encounter.
        </li>
        <li>
          <strong>Not a credential.</strong> There are no CME credits, certificates,
          or formal assessments. The value is in what you learn, not what you earn.
        </li>
      </ul>

      <h2>Time Investment</h2>
      <p>
        Each module takes roughly <strong>2-4 hours</strong> to complete, depending
        on how deeply you engage with the readings and activities. The full guide
        represents about 30-40 hours of learning—but there's no pressure to complete
        it all. Even one or two modules will give you useful frameworks.
      </p>

      <!-- How This Course Was Made -->
      <h2>How This Course Was Made</h2>
      <p>
        This course about AI was built with AI. That's not a confession—it's the point.
      </p>

      <h3>The Process</h3>
      <p>
        Every module you've read emerged from a collaboration between a physician (me)
        and a large language model (Claude, made by Anthropic). The workflow looked
        something like this:
      </p>
      <ol>
        <li>I created an outline based on what I thought clinicians actually needed to know</li>
        <li>I wrote a detailed prompt describing the audience, tone, and learning objectives</li>
        <li>Claude generated a draft</li>
        <li>I reviewed, pushed back, asked for revisions, cut what didn't work, and added what was missing</li>
        <li>Repeat until it felt right</li>
      </ol>
      <p>
        Replit helped format and publish the website. The whole thing came together in
        a fraction of the time it would have taken me to write alone—and, I'd argue,
        with better results than either of us could have produced independently.
      </p>

      <h3>A Small Experiment</h3>
      <p>
        Here's a challenge: one module in this course was written entirely by AI with
        minimal editing. Another was written entirely by me, with no AI assistance.
        Can you tell which is which?
      </p>
      <p>
        Most people can't—at least not reliably. That's not because AI writing is
        indistinguishable from human writing (it often isn't, once you know what to look for).
        It's because the <em>process</em> matters more than the <em>origin</em>. A well-prompted,
        carefully edited AI draft can read better than a rushed human one. A thoughtful human
        piece can have qualities AI still struggles to replicate. The interesting question
        isn't "who wrote this?" but "is this good, accurate, and useful?"
      </p>

      <div class="callout callout-warning">
        <div class="callout-title">The Catch</div>
        <p>
          There's a reason this course emphasizes verification, and I'm going to illustrate
          it directly: somewhere in these modules are <strong>three completely fabricated
          references</strong>. They look real. They're formatted correctly. They sound plausible.
          But the studies don't exist.
        </p>
        <p>
          I put them there on purpose.
        </p>
        <p>
          If you've been reading carefully and checking sources, you may have already caught
          them. If you haven't—well, now you know why the "trust but verify" principle isn't
          just a slogan. AI can generate confident, well-structured, entirely fictional
          citations without blinking. So can humans, for that matter, but AI makes it effortless
          in a way that changes the risk calculus.
        </p>
        <p class="mb-0">
          An answer key will be provided so you can check your work.
        </p>
      </div>

      <h3>What This Means for You</h3>
      <p>
        This course argues that AI is a tool—powerful, useful, and only as good as
        the human directing it. The course itself is evidence of that claim.
      </p>
      <p>
        The modules exist because I knew what questions to ask, what structure would
        serve learners, and what needed to be cut or rewritten. They're better than
        what I'd have written alone because AI can draft quickly, suggest framings I
        wouldn't have considered, and maintain consistency across sections in ways that
        are tedious for humans.
      </p>
      <p>
        Neither of us could have done this alone. Both of us were necessary.
      </p>

      <div class="callout callout-principle">
        <div class="callout-title">The Partnership Model</div>
        <p class="mb-0">
          That's the partnership this course is trying to help you build with AI in your
          own work. Not replacement. Not magic. Just a capable collaborator that requires
          your judgment to be useful—and your vigilance to be safe.
        </p>
      </div>

      <hr>

      <h2>Acknowledgments</h2>
      <p>
        This guide was developed with input and inspiration from colleagues
        working at the intersection of medicine and AI:
      </p>
      <ul>
        <li><a href="https://www.xprimarycare.com/" target="_blank">XPC (XPrimaryCare)</a></li>
        <li><a href="https://www.linkedin.com/in/davidhardinmd/" target="_blank">Dr. Dave Hardin</a></li>
        <li><a href="https://www.linkedin.com/in/graham-walker-md/" target="_blank">Dr. Graham Walker</a></li>
        <li><a href="https://www.linkedin.com/in/pauliusmui/" target="_blank">Dr. Paulius Mui</a></li>
        <li><a href="https://www.linkedin.com/in/mishamanulis/" target="_blank">Misha Manulis</a></li>
      </ul>

      <hr>

      <h2>Feedback</h2>
      <p>
        Found an error? Have a suggestion? Questions about the process?
        <a href="#">Get in touch →</a>
      </p>

    </article>
  </main>

  <footer class="footer">
    <div class="footer-inner">
      <div><strong>AI 101</strong> · A Self-Paced Guide to AI in Medicine</div>
      <div>v1.0 · 2025</div>
    </div>
  </footer>

  <script>
    lucide.createIcons();
    const navToggle = document.querySelector('.nav-toggle');
    const navLinks = document.querySelector('.nav-links');
    if (navToggle) {
      navToggle.addEventListener('click', () => {
        navLinks.classList.toggle('nav-open');
      });
    }
  </script>

  <script src="https://studio.pickaxe.co/api/embed/bundle.js" defer></script>

</body>
</html>
