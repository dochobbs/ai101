<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Week 11: Module 18: Patient Communication | AI 101</title>
  <link rel="stylesheet" href="styles.css">
  <script src="https://unpkg.com/lucide@latest"></script>
</head>
<body>

  <nav class="nav">
    <div class="nav-inner">
      <a href="index.html" class="nav-brand">
        <span class="nav-badge">AI 101</span>
        <span class="nav-title">A Self-Paced Guide to AI in Medicine</span>
      </a>
      <button class="nav-toggle" aria-label="Toggle menu">
        <i data-lucide="menu"></i>
      </button>
      <div class="nav-links">
        <a href="index.html" class="nav-link">Modules</a>
        <!-- <a href="resources.html" class="nav-link">Resources</a> -->
        <a href="about.html" class="nav-link">About</a>
      </div>
    </div>
  </nav>

  <main class="main">
    <article class="content">

      <header class="unit-header">
        <span class="unit-label phase-3">PHASE III 路 MODULE 18</span>
        <h1 class="unit-title">Patient Communication</h1>
        <p class="unit-subtitle">
          Informed consent for AI-assisted care, transparency frameworks,
          and managing patient expectations.
        </p>
        <div class="unit-meta">
          <span class="unit-meta-item">
            <i data-lucide="book-open"></i>
            4 readings
          </span>
        </div>
      </header>

      <div class="callout callout-question">
        <div class="callout-title">Core Question</div>
        <p class="mb-0">
          What do patients need to know about AI in their careand how do we 
          explain it in ways that are honest without being alarming?
        </p>
      </div>

      <h2>Overview</h2>
      <p>
        Patients are increasingly aware that AI is entering healthcare, but 
        their understanding varies wildlyfrom science fiction fears to 
        unrealistic expectations of infallibility. This week addresses the 
        communication challenges: when to disclose AI use, how to explain it, 
        and how to obtain meaningful informed consent for AI-assisted care.
      </p>

      <h2>Key Concepts</h2>

      <h3>The Disclosure Debate</h3>
      <p>
        Should patients be told every time AI influences their care? Arguments 
        exist on both sides:
      </p>
      <ul>
        <li>
          <strong>For disclosure:</strong> Patients have a right to know what 
          tools affect their care; transparency builds trust; some patients 
          may have strong preferences about AI use.
        </li>
        <li>
          <strong>Against routine disclosure:</strong> AI is increasingly 
          pervasive (do we disclose every software system?); disclosure may 
          cause unnecessary anxiety; patients may lack context to meaningfully 
          evaluate AI use.
        </li>
      </ul>
      <p>
        A middle path: disclose AI use when it materially affects clinical 
        decisions, when patients specifically ask, or when AI is the primary 
        diagnostic or treatment recommendation (not just a supporting tool).
      </p>

      <h3>Informed Consent Frameworks</h3>
      <p>
        Traditional informed consent requires explaining risks, benefits, and 
        alternatives. For AI, this might include:
      </p>
      <ul>
        <li>What the AI does and what data it uses</li>
        <li>The AI's accuracy and error rates, if known</li>
        <li>How the clinician uses AI output (supporting tool vs. primary driver)</li>
        <li>Options if the patient prefers care without AI involvement</li>
        <li>How patient data may be used for AI improvement</li>
      </ul>
      <p>
        Practically, this can't be a 10-minute conversation for every AI 
        encounter. Institutions may need tiered approaches: general consent 
        covering routine AI use, specific consent for high-stakes AI decisions.
      </p>

      <h3>Managing Expectations</h3>
      <p>
        Some patients will expect AI to be infallible ("the computer must be 
        right"). Others will distrust AI entirely ("I want a human doctor"). 
        Effective communication navigates both:
      </p>
      <ul>
        <li>AI is a tool that helps me provide better care, not a replacement for my judgment</li>
        <li>AI can catch things I might miss, but it can also make mistakesthat's why I review its suggestions</li>
        <li>You're always welcome to ask about how I'm using AI in your care</li>
      </ul>

      <div class="callout callout-principle">
        <div class="callout-title">Communication Principle</div>
        <p class="mb-0">
          Patients don't need to understand how algorithms workbut they do 
          need to understand that you, their clinician, remain responsible 
          for their care and are thoughtfully supervising any AI tools involved.
        </p>
      </div>

      <h2>Readings</h2>
      <div class="reading-list">
        <div class="reading-item">
          <div class="reading-type"></div>
          <div class="reading-content">
            <div class="reading-title">
              Esmaeilzadeh, P. "Use of AI-based tools for healthcare purposes: a survey study from consumers' perspectives"

            </div>
            <div class="reading-meta">BMC Medical Informatics, 2020 路 Patient attitudes toward AI</div>
          </div>
        </div>
        <div class="reading-item">
          <div class="reading-type"></div>
          <div class="reading-content">
            <div class="reading-title">
              Cohen, I.G. "Informed Consent and Medical Artificial Intelligence"

            </div>
            <div class="reading-meta">Georgetown Law Journal, 2020</div>
          </div>
        </div>
        <div class="reading-item">
          <div class="reading-type"></div>
          <div class="reading-content">
            <div class="reading-title">
              Lennartz, S. et al. "Use and Control of Artificial Intelligence in Patients Across the Medical Workflow"

            </div>
            <div class="reading-meta">Radiology: AI, 2021</div>
          </div>
        </div>
        <div class="reading-item">
          <div class="reading-type"></div>
          <div class="reading-content">
            <div class="reading-title">
              Seh, A.H. et al. "Healthcare Data Breaches: Insights and Implications"

            </div>
            <div class="reading-meta">Healthcare, 2020 路 Context on data privacy concerns</div>
          </div>
        </div>
      </div>

      <h2>Sample Disclosure Language</h2>
      
      <h3>Routine AI Use (Brief Mention)</h3>
      <div class="prompt-box">"I'm using a computer tool that helps me review your 
images/lab results. It flags things for me to look at 
more closely. I always review its suggestions myself 
before making any decisions about your care."</div>

      <h3>AI-Driven Recommendation (More Detail)</h3>
      <div class="prompt-box">"A computer analysis of your scan suggests [finding]. 
These tools are helpful but not perfectthey can miss 
things and sometimes flag things that turn out to be 
nothing. I've reviewed the results and here's what I 
think we should do..."</div>

      <h3>Response to Patient Concern</h3>
      <div class="prompt-box">"I understand you have concerns about AI. You should 
know that I make all the final decisions about your 
care. The AI helps me by processing large amounts of 
data, but I always apply my clinical judgment. If you 
prefer, we can discuss specifically how AI is being 
used in your care."</div>

      <div class="discussion-questions">
        <h4>Discussion Questions</h4>
        <ol>
          <li>
            A patient says "I don't want any AI involved in my care." 
            How do you respond? Is this request even feasible given 
            how integrated AI is becoming?
          </li>
          <li>
            Should there be different disclosure standards for AI that 
            diagnoses (high stakes) vs. AI that drafts documentation 
            (lower stakes)?
          </li>
          <li>
            A patient's family member asks "Was a computer involved in 
            the decision that led to this outcome?" after a poor result. 
            How do you answer?
          </li>
        </ol>
      </div>

      <div class="objectives phase-3">
        <h4 class="objectives-title">Learning Objectives</h4>
        <ul class="objectives-list">
          <li>Articulate when and how to disclose AI use to patients</li>
          <li>Apply informed consent principles to AI-assisted care</li>
          <li>Use clear, non-technical language to explain AI's role</li>
          <li>Address patient concerns about AI with honesty and reassurance</li>
        </ul>
      </div>

      <nav class="page-nav">
        <a href="week-10.html" class="page-nav-link prev">
          <span class="page-nav-arrow"><i data-lucide="arrow-left"></i></span>
          <div>
            <span class="page-nav-label">Previous</span>
            <span class="page-nav-title">Module 17: Institutional Governance</span>
          </div>
        </a>
        <a href="week-12.html" class="page-nav-link next">
          <span class="page-nav-arrow"><i data-lucide="arrow-right"></i></span>
          <div>
            <span class="page-nav-label">Next</span>
            <span class="page-nav-title">Module 19: Future Horizons</span>
          </div>
        </a>
      </nav>

    </article>
  </main>

  <footer class="footer">
    <div class="footer-inner">
      <div><strong>AI 101</strong> 路 A Self-Paced Guide to AI in Medicine</div>
      <div>v1.0 路 2025</div>
    </div>
  </footer>

  <script>
    lucide.createIcons();
    const navToggle = document.querySelector('.nav-toggle');
    const navLinks = document.querySelector('.nav-links');
    if (navToggle) {
      navToggle.addEventListener('click', () => {
        navLinks.classList.toggle('nav-open');
      });
    }
  </script>

  <div id="deployment-ad427d94-d946-433a-b50b-40045a2266b7"></div>
  <script src="https://studio.pickaxe.co/api/embed/bundle.js" defer></script>

</body>
</html>
