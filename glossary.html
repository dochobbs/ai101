<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>AI Glossary & Learning Resources | AI 101</title>
  <link rel="stylesheet" href="styles.css">
  <script src="https://unpkg.com/lucide@latest"></script>
</head>
<body>

  <nav class="nav">
    <div class="nav-inner">
      <a href="index.html" class="nav-brand">
        <span class="nav-badge">AI 101</span>
        <span class="nav-title">A Self-Paced Guide to AI in Medicine</span>
      </a>
      <button class="nav-toggle" aria-label="Toggle menu">
        <i data-lucide="menu"></i>
      </button>
      <div class="nav-links">
        <a href="index.html" class="nav-link">Topics</a>
        <!-- <a href="resources.html" class="nav-link">Resources</a> -->
        <a href="about.html" class="nav-link">About</a>
        <a href="contribute.html" class="nav-link">Contribute</a>
        <div id="deployment-1fa153eb-d95d-460c-9711-c41a3f103961" class="nav-chatbot"></div>
      </div>
    </div>
  </nav>

  <main class="main">
    <article class="content content-wide">

      <header class="unit-header">
        <span class="unit-label appendix">RESOURCES</span>
        <h1 class="unit-title">AI Glossary</h1>
        <p class="unit-subtitle">
          The acronyms you'll actually encounter—organized from foundational
          concepts to specialized terms, with explanations of why each matters.
        </p>
        <div class="unit-meta">
          <span class="unit-meta-item">
            <i data-lucide="book-open"></i>
            Reference guide
          </span>
        </div>
      </header>

      <p>
        This glossary covers the terminology you'll see in product documentation,
        news articles, and conversations about AI. Each entry explains not just
        <em>what</em> something is, but <em>why it matters</em> for practical use.
      </p>

      <!-- Quick Navigation -->
      <div class="glossary-nav">
        <strong>Jump to:</strong>
        <a href="#foundational">Foundational Concepts</a> ·
        <a href="#language-models">Language Models</a> ·
        <a href="#interaction">How You Interact</a> ·
        <a href="#prompting">Prompting Techniques</a> ·
        <a href="#training">Training & Customization</a> ·
        <a href="#applications">Applications & Agents</a> ·
        <a href="#evaluation">Evaluation & Safety</a> ·
        <a href="#companies">Companies & Models</a> ·
        <a href="#infrastructure">Infrastructure</a> ·
        <a href="#emerging">Emerging Terms</a> ·
        <a href="#healthcare">Healthcare AI</a> ·
        <a href="#resources">Learning Resources</a>
      </div>

      <hr>

      <!-- Foundational Concepts -->
      <h2 id="foundational">Foundational Concepts</h2>

      <dl class="glossary-list">
        <div class="glossary-item">
          <dt>AI (Artificial Intelligence)</dt>
          <dd>
            The broad field of creating systems that can perform tasks typically
            requiring human intelligence—learning, reasoning, problem-solving,
            perception. When people say "AI" today, they usually mean
            generative AI or LLMs specifically, but the term encompasses everything
            from chess engines to self-driving cars.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>ML (Machine Learning)</dt>
          <dd>
            A subset of AI where systems learn patterns from data rather than
            following explicit programming rules. Instead of telling a computer
            "if X, then Y," you show it thousands of examples and let it figure
            out the patterns. Most modern AI is built on ML techniques.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>DL (Deep Learning)</dt>
          <dd>
            A subset of machine learning using neural networks with multiple
            layers (hence "deep"). These architectures excel at finding complex
            patterns in large datasets—the breakthrough that enabled modern AI
            capabilities like image recognition and natural language understanding.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>GenAI (Generative AI)</dt>
          <dd>
            AI systems that create new content—text, images, audio, video, code—rather
            than just analyzing or classifying existing data. ChatGPT, Claude,
            Midjourney, and DALL-E are all generative AI tools. This is the category
            driving most current AI adoption.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>AGI (Artificial General Intelligence)</dt>
          <dd>
            A hypothetical AI system with human-level reasoning across all domains—not
            just narrow expertise in specific tasks. Current AI systems are "narrow AI"
            (excellent at specific things, unable to generalize). AGI remains a research
            goal, not a current reality. Claims about AGI timelines vary wildly and
            should be viewed skeptically.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>Reasoning Models</dt>
          <dd>
            A new category of AI models designed to "think" through problems step-by-step
            before responding. OpenAI's o1 and o3 models, Claude's extended thinking mode,
            and Google's Gemini 2.0 Flash Thinking exemplify this approach. They trade speed
            for accuracy on complex tasks by using more compute at inference time.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>Inference-Time Compute (Test-Time Compute)</dt>
          <dd>
            The computational resources used when a model generates a response, as opposed
            to during training. Reasoning models use significantly more inference-time compute
            to "think longer" about difficult problems. A major 2025 research direction—some
            argue it's as important as scaling training data.
          </dd>
        </div>
      </dl>

      <hr>

      <!-- Language Models and Architecture -->
      <h2 id="language-models">Language Models and Architecture</h2>

      <dl class="glossary-list">
        <div class="glossary-item">
          <dt>LLM (Large Language Model)</dt>
          <dd>
            Neural networks trained on massive text datasets to understand and
            generate human language. "Large" refers to billions of parameters
            (adjustable values the model learned during training). GPT-4, Claude,
            Gemini, and Llama are all LLMs. These models power most text-based
            AI tools you'll encounter.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>SLM (Small Language Model)</dt>
          <dd>
            Smaller, more efficient language models designed to run on limited
            hardware or for specific tasks. Typically millions rather than billions
            of parameters. Useful when you need speed, privacy (local processing),
            or can't afford cloud API costs.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>VLM (Vision Language Model)</dt>
          <dd>
            Models that process both images and text, understanding relationships
            between visual and linguistic information. GPT-4 with vision, Claude's
            image analysis, and Gemini are VLMs. Enable features like describing
            images, analyzing charts, or discussing visual content.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>Transformer</dt>
          <dd>
            The neural network architecture underlying virtually all modern LLMs.
            Introduced in 2017, it uses "self-attention" to process relationships
            between all parts of input text simultaneously rather than sequentially.
            The "T" in GPT, BERT, and many other model names stands for Transformer.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>GPT (Generative Pre-trained Transformer)</dt>
          <dd>
            OpenAI's family of language models—GPT-3, GPT-4, etc. The name describes
            the architecture: generative (creates text), pre-trained (learned from
            massive data before fine-tuning), transformer (the underlying architecture).
            Often used generically to mean any LLM, though technically it's OpenAI's
            product line.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>BERT (Bidirectional Encoder Representations from Transformers)</dt>
          <dd>
            A Google model architecture that reads text in both directions
            simultaneously—understanding context from what comes before <em>and</em>
            after each word. Primarily used for understanding tasks (classification,
            search) rather than generation. The architecture behind much of Google
            Search's language understanding.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>Parameters</dt>
          <dd>
            The adjustable numerical values within a neural network that the model
            learns during training. More parameters generally mean more capacity to
            learn patterns, but also more computational cost. GPT-4 reportedly has
            over a trillion parameters; Claude and other frontier models are similar scale.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>Weights</dt>
          <dd>
            Essentially synonymous with parameters in common usage—the numerical
            values that define how a model processes information. "Model weights"
            refers to the complete set of learned parameters that make up a trained model.
          </dd>
        </div>
      </dl>

      <hr>

      <!-- How You Interact with AI -->
      <h2 id="interaction">How You Interact with AI</h2>

      <dl class="glossary-list">
        <div class="glossary-item">
          <dt>Prompt</dt>
          <dd>
            Any input you give to an AI model—a question, instruction, document,
            or combination. The quality and structure of your prompt significantly
            affects output quality. "Prompting" has become a skill category unto itself.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>System Prompt</dt>
          <dd>
            Instructions set by developers that establish an AI's baseline behavior,
            persona, or constraints—typically invisible to end users. When you use
            ChatGPT, a system prompt tells it to be helpful and follow safety guidelines.
            System prompts shape the AI's "personality" and capabilities within a
            given application.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>Context Window</dt>
          <dd>
            The maximum amount of text an LLM can process at once—both your input
            and its output combined. Measured in tokens (roughly 3/4 of a word).
            GPT-4 Turbo has a 128K context window (~100,000 words); Claude's standard
            context is 200K tokens, with some models supporting up to 1M tokens.
            Larger context windows enable working with longer documents and conversations.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>Token</dt>
          <dd>
            The basic unit LLMs use to process text—typically word fragments rather
            than whole words. "Tokenization" converts text into these chunks.
            Understanding tokens matters for: context window limits, API pricing
            (often per-token), and why character counts sometimes behave strangely
            (the model doesn't "see" individual characters).
          </dd>
        </div>

        <div class="glossary-item">
          <dt>Temperature</dt>
          <dd>
            A setting controlling how "creative" or "random" model outputs are.
            Low temperature (0-0.3) produces more predictable, conservative responses;
            high temperature (0.7-1.0) produces more varied, creative outputs. Useful
            for different tasks—low for factual retrieval, higher for creative writing.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>Hallucination</dt>
          <dd>
            When an AI generates plausible-sounding but factually incorrect information
            with apparent confidence. Named because the model "sees" patterns that
            aren't there. A fundamental limitation of current LLMs—they optimize for
            coherent language, not truth. <strong>Always verify important facts.</strong>
          </dd>
        </div>

        <div class="glossary-item">
          <dt>Tool Use (Function Calling)</dt>
          <dd>
            The ability for AI models to interact with external tools, APIs, and services.
            Instead of just generating text, the model can search the web, run code, query
            databases, or control other software. Enables AI to take actions, not just
            provide information. Foundation for AI agents.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>MCP (Model Context Protocol)</dt>
          <dd>
            Anthropic's open protocol that standardizes how AI applications connect to
            external data sources and tools. Think of it as a universal adapter—instead
            of building custom integrations for each tool, MCP provides a common interface.
            Gaining adoption across AI tools in 2025.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>Artifacts</dt>
          <dd>
            Interactive outputs that Claude can create—code, documents, diagrams, or
            applications—that appear in a separate panel and can be edited, copied, or
            downloaded. Enables Claude to produce working prototypes, not just descriptions.
            A key feature for vibe coding and rapid prototyping.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>Extended Thinking</dt>
          <dd>
            Claude's reasoning mode where the model shows its step-by-step thinking process
            before providing a final answer. Uses more inference-time compute to work through
            complex problems. Particularly useful for math, logic, and multi-step reasoning tasks.
          </dd>
        </div>
      </dl>

      <hr>

      <!-- Prompting Techniques -->
      <h2 id="prompting">Prompting Techniques</h2>

      <dl class="glossary-list">
        <div class="glossary-item">
          <dt>Zero-shot Prompting</dt>
          <dd>
            Asking an AI to perform a task without providing examples—just instructions.
            "Translate this to French: Hello, how are you?" The model applies its
            training directly without additional context.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>Few-shot Prompting (In-Context Learning)</dt>
          <dd>
            Providing several examples of the desired input/output format before
            your actual request. The model learns the pattern from your examples
            and applies it. Often dramatically improves performance on structured tasks.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>Chain-of-Thought (CoT) Prompting</dt>
          <dd>
            Asking the model to show its reasoning step-by-step rather than jumping
            to conclusions. Adding "Let's think through this step by step" can
            significantly improve performance on complex reasoning tasks. The model's
            explicit reasoning also makes errors easier to catch.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>Prompt Engineering</dt>
          <dd>
            The practice of systematically designing and refining prompts to get
            better AI outputs. Involves understanding how models interpret instructions,
            what context helps, and how to structure requests for optimal results.
            More art than science, but with learnable patterns.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>Prompt Chaining</dt>
          <dd>
            Breaking complex tasks into sequential steps, where each prompt builds
            on previous outputs. Instead of one massive prompt, you guide the model
            through a workflow. Reduces errors and gives you checkpoints to verify quality.
          </dd>
        </div>
      </dl>

      <hr>

      <!-- Model Training and Customization -->
      <h2 id="training">Model Training and Customization</h2>

      <dl class="glossary-list">
        <div class="glossary-item">
          <dt>Pre-training</dt>
          <dd>
            The initial, massive training phase where a model learns general language
            patterns from vast text datasets. Pre-training gives models their foundational
            capabilities. OpenAI, Anthropic, Google, and others invest millions in
            pre-training runs that take months on thousands of GPUs.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>Fine-tuning</dt>
          <dd>
            Additional training on a smaller, task-specific dataset to adapt a
            pre-trained model for particular uses. A hospital might fine-tune a
            model on medical records; a company might fine-tune on their internal
            documentation. Less expensive than pre-training from scratch.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>RLHF (Reinforcement Learning from Human Feedback)</dt>
          <dd>
            A training technique where humans rate model outputs, and these ratings
            guide further learning. Used to align models with human preferences—making
            them more helpful, less harmful, and more honest. A key technique that
            made ChatGPT dramatically more usable than its predecessors.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>Alignment</dt>
          <dd>
            The goal of making AI systems behave according to human values and
            intentions. "Misaligned" AI might technically follow instructions while
            violating their spirit, or optimize for metrics that don't match what
            humans actually want. Central concern in AI safety research.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>LoRA (Low-Rank Adaptation)</dt>
          <dd>
            A technique for fine-tuning large models efficiently by training a
            small set of adapter weights rather than modifying the entire model.
            Makes customization feasible for organizations without massive computing budgets.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>RAG (Retrieval-Augmented Generation)</dt>
          <dd>
            A technique where the model retrieves relevant information from a
            knowledge base before generating responses. Rather than relying solely
            on what the model "memorized" during training, RAG lets it access current,
            specific data. Powers many enterprise AI applications and reduces hallucinations.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>Embeddings</dt>
          <dd>
            Numerical representations of text that capture semantic meaning—similar
            concepts have similar embeddings. Enables semantic search (finding relevant
            content by meaning, not just keywords) and are fundamental to RAG systems.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>Vector Database</dt>
          <dd>
            Databases optimized for storing and searching embeddings. When you ask
            an AI about your company's documents, a vector database helps find relevant
            passages quickly. Pinecone, Weaviate, and Chroma are common examples.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>RLAIF (Reinforcement Learning from AI Feedback)</dt>
          <dd>
            Similar to RLHF, but using AI-generated feedback instead of human ratings
            to guide training. More scalable than human feedback. Anthropic's Constitutional
            AI uses this approach—Claude evaluates its own outputs against principles.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>DPO (Direct Preference Optimization)</dt>
          <dd>
            A simpler alternative to RLHF that directly optimizes models on preference
            data without needing a separate reward model. Increasingly popular for
            fine-tuning because it's more stable and computationally efficient.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>Distillation</dt>
          <dd>
            Transferring knowledge from a large "teacher" model to a smaller "student"
            model. The smaller model learns to mimic the larger model's outputs, achieving
            similar performance at lower cost. How many efficient local models are created.
          </dd>
        </div>
      </dl>

      <hr>

      <!-- AI Applications and Agents -->
      <h2 id="applications">AI Applications and Agents</h2>

      <dl class="glossary-list">
        <div class="glossary-item">
          <dt>NLP (Natural Language Processing)</dt>
          <dd>
            The field of AI focused on enabling computers to understand, interpret,
            and generate human language. LLMs represent the current state-of-the-art
            in NLP. Encompasses tasks like translation, summarization, sentiment
            analysis, and question-answering.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>NLU (Natural Language Understanding)</dt>
          <dd>
            A subset of NLP specifically focused on comprehension—extracting meaning,
            intent, and entities from text. Distinguished from generation; NLU is
            about understanding what someone means.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>Chatbot</dt>
          <dd>
            An AI system designed for conversational interaction. Modern chatbots
            (ChatGPT, Claude, Gemini) use LLMs for open-ended conversation; older
            chatbots used simpler rules or intent-matching. The interface through
            which most people experience AI.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>AI Agent</dt>
          <dd>
            An AI system that can take actions autonomously—browsing the web,
            executing code, calling APIs, managing files—rather than just generating
            text. The frontier of current AI development. Agents chain together
            planning, tool use, and execution to accomplish complex goals.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>Agentic AI</dt>
          <dd>
            AI systems designed for autonomous, multi-step task completion with
            minimal human intervention. More proactive than traditional assistants—they
            break down goals, plan approaches, and adapt to obstacles. Claude's computer
            use feature and similar capabilities represent early agentic AI.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>MoE (Mixture of Experts)</dt>
          <dd>
            An architecture where multiple specialized "expert" sub-networks activate
            selectively based on the input. Allows models to be larger and more capable
            while keeping computation costs manageable—not every expert activates for
            every query.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>Multimodal</dt>
          <dd>
            AI systems that process multiple types of input—text, images, audio, video.
            GPT-4V, Claude's image understanding, and Gemini are multimodal. The trend
            is toward models that understand the world through multiple "senses" like
            humans do.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>Vibe Coding</dt>
          <dd>
            Building software by describing what you want in natural language and letting
            AI generate the code—without necessarily reading or understanding the code yourself.
            Coined by Andrej Karpathy in February 2025 and named Collins Dictionary's Word of
            the Year. Tools like Replit, Lovable, and Claude Code enable this approach.
            <a href="vibe-coding.html">See our full module on vibe coding.</a>
          </dd>
        </div>

        <div class="glossary-item">
          <dt>Custom GPTs / Gems / Projects</dt>
          <dd>
            Customizable AI assistants created by users for specific purposes. OpenAI calls
            them "Custom GPTs," Google calls them "Gems," and Anthropic uses "Projects."
            You define instructions, upload reference documents, and create a specialized
            assistant without coding. Great for creating patient-facing tools or
            specialty-specific assistants.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>Computer Use</dt>
          <dd>
            AI capability to control desktop interfaces—clicking, typing, navigating
            applications like a human would. Claude's computer use feature and similar
            tools enable AI to interact with any software, not just API-connected services.
            An early but rapidly developing capability.
          </dd>
        </div>
      </dl>

      <hr>

      <!-- Evaluation and Safety -->
      <h2 id="evaluation">Evaluation and Safety</h2>

      <dl class="glossary-list">
        <div class="glossary-item">
          <dt>Eval (Evaluation)</dt>
          <dd>
            Systematic testing of AI model performance on defined benchmarks or tasks.
            Evals help compare models, track improvements, and identify weaknesses.
            "Running evals" is standard practice in AI development.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>Benchmark</dt>
          <dd>
            Standardized tests for comparing AI model capabilities—MMLU (general
            knowledge), HumanEval (coding), HellaSwag (common sense reasoning).
            Useful for rough comparisons but can be gamed and don't always reflect
            real-world performance.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>Guardrails</dt>
          <dd>
            Technical controls that prevent AI systems from generating harmful,
            inappropriate, or off-topic content. Can include content filters,
            output validation, and behavioral constraints embedded in system prompts.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>Red Teaming</dt>
          <dd>
            Deliberately trying to break AI systems to find vulnerabilities before
            malicious actors do. Includes prompt injection attacks, jailbreaking
            attempts, and stress-testing safety measures. Important for responsible
            AI deployment.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>Prompt Injection</dt>
          <dd>
            Attacks where malicious instructions hidden in input data attempt to
            override an AI's intended behavior. A security concern for AI applications—an
            email might contain hidden instructions that manipulate an AI email assistant.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>Jailbreaking</dt>
          <dd>
            Techniques to bypass an AI model's safety measures and get it to produce
            content it would normally refuse. Often involves clever prompt manipulation
            or roleplay scenarios. A constant cat-and-mouse game between AI developers
            and those attempting to circumvent safeguards.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>Refusal</dt>
          <dd>
            When an AI model declines to respond to a request, typically because it
            violates safety guidelines. "I can't help with that" responses. Models are
            trained to refuse harmful, illegal, or inappropriate requests. Sometimes
            models refuse too cautiously (false positives) or not enough (false negatives).
          </dd>
        </div>

        <div class="glossary-item">
          <dt>Common Benchmarks</dt>
          <dd>
            <strong>MMLU</strong> (Massive Multitask Language Understanding): Tests knowledge
            across 57 subjects from elementary to professional level.<br>
            <strong>GPQA</strong> (Graduate-Level Google-Proof Q&A): PhD-level science questions
            that can't be easily Googled.<br>
            <strong>HumanEval / SWE-bench</strong>: Coding ability tests—writing functions and
            solving real GitHub issues.<br>
            <strong>MedQA</strong>: Medical licensing exam questions, relevant for healthcare AI.
          </dd>
        </div>
      </dl>

      <hr>

      <!-- Companies and Models -->
      <h2 id="companies">Companies and Models You'll Encounter</h2>

      <div class="company-grid">
        <div class="company-card">
          <h4>OpenAI</h4>
          <p>Created GPT-4, ChatGPT, DALL-E, o1/o3 reasoning models. The company most
          associated with the current AI boom. Partnered with Microsoft.</p>
        </div>
        <div class="company-card">
          <h4>Anthropic</h4>
          <p>Created Claude. Founded by former OpenAI researchers focused on AI safety.
          Notable for constitutional AI, extended thinking, and computer use capabilities.</p>
        </div>
        <div class="company-card">
          <h4>Google/DeepMind</h4>
          <p>Created Gemini, PaLM, BERT. Deep research heritage. DeepMind created
          AlphaFold (protein structure) and AlphaGo. Gemini 2.0 leads in multimodal.</p>
        </div>
        <div class="company-card">
          <h4>Meta</h4>
          <p>Created Llama (open-source LLMs). Major contributor to open AI research.
          Llama models power many local and fine-tuned applications.</p>
        </div>
        <div class="company-card">
          <h4>xAI</h4>
          <p>Elon Musk's AI company. Created Grok, integrated into X (Twitter).
          Known for fewer content restrictions than competitors.</p>
        </div>
        <div class="company-card">
          <h4>Mistral</h4>
          <p>French AI company with strong open-source models. Known for efficient
          architectures that compete with larger proprietary models.</p>
        </div>
        <div class="company-card">
          <h4>Cohere</h4>
          <p>Enterprise-focused AI company. Strong in RAG, embeddings, and business
          applications. Popular for companies building AI into products.</p>
        </div>
        <div class="company-card">
          <h4>Perplexity</h4>
          <p>AI-powered search engine that answers questions with citations.
          Combines LLMs with real-time web search. Growing alternative to Google.</p>
        </div>
      </div>

      <hr>

      <!-- Infrastructure and Operations -->
      <h2 id="infrastructure">Infrastructure and Operations</h2>

      <dl class="glossary-list">
        <div class="glossary-item">
          <dt>API (Application Programming Interface)</dt>
          <dd>
            How developers integrate AI models into their applications. OpenAI,
            Anthropic, and others offer APIs where you send prompts and receive
            completions programmatically. API access is usually priced per token.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>GPU (Graphics Processing Unit)</dt>
          <dd>
            The specialized processors that power AI training and inference.
            Originally designed for graphics rendering, their parallel processing
            architecture is ideal for neural networks. NVIDIA dominates the AI GPU market.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>Inference</dt>
          <dd>
            Running a trained model to generate outputs—what happens when you chat
            with an AI. Distinguished from training. Inference is much cheaper than
            training but still computationally intensive at scale.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>Latency</dt>
          <dd>
            The delay between sending a request and receiving a response. Lower
            latency means faster, more responsive AI applications. Measured in milliseconds.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>Knowledge Cutoff</dt>
          <dd>
            The date beyond which a model has no training data. If a model's knowledge
            cutoff is January 2024, it doesn't "know" about events after that date.
            Web search and RAG help address this limitation.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>TPU (Tensor Processing Unit)</dt>
          <dd>
            Google's custom AI chips, designed specifically for machine learning workloads.
            An alternative to NVIDIA GPUs. Google uses TPUs to train and run Gemini models.
            Amazon (Trainium) and others are developing similar custom AI chips.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>Quantization</dt>
          <dd>
            Reducing the precision of model weights (e.g., from 32-bit to 4-bit numbers)
            to shrink model size and speed up inference. Makes large models runnable on
            consumer hardware. Essential for local AI—a quantized Llama model can run on
            a laptop that couldn't handle the full-precision version.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>GGUF</dt>
          <dd>
            A file format for storing quantized language models, commonly used for local
            AI applications. If you see a model file ending in .gguf, it's designed to
            run locally with tools like Ollama or LM Studio. Successor to the older GGML format.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>Ollama</dt>
          <dd>
            Popular open-source tool for running LLMs locally on your computer. Handles
            model downloading, quantization, and provides a simple interface. The easiest
            way to experiment with local AI. <a href="local-models.html">See our module
            on running local models.</a>
          </dd>
        </div>
      </dl>

      <hr>

      <!-- Emerging Terms -->
      <h2 id="emerging">Emerging Terms Worth Knowing</h2>

      <dl class="glossary-list">
        <div class="glossary-item">
          <dt>Foundation Model</dt>
          <dd>
            Large models trained on broad data that can be adapted for many downstream
            tasks. GPT-4 and Claude are foundation models.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>Synthetic Data</dt>
          <dd>
            AI-generated data used to train other AI systems. Increasingly used when
            real data is scarce, expensive, or privacy-sensitive.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>Model Collapse</dt>
          <dd>
            A theoretical concern where models trained on AI-generated data progressively
            degrade in quality. An argument for maintaining human-generated training data.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>Constitutional AI</dt>
          <dd>
            Anthropic's approach to alignment where models are trained with explicit
            principles rather than just human ratings.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>Context Engineering</dt>
          <dd>
            The emerging practice of systematically managing everything that goes
            into a model's context window—prompts, examples, retrieved documents,
            conversation history.
          </dd>
        </div>
      </dl>

      <hr>

      <!-- Healthcare AI Terms -->
      <h2 id="healthcare">Healthcare AI Terms</h2>

      <p>
        Terms specific to AI applications in clinical settings—the vocabulary you'll
        encounter in health system AI initiatives, vendor pitches, and medical literature.
      </p>

      <dl class="glossary-list">
        <div class="glossary-item">
          <dt>AI Scribe (Ambient AI)</dt>
          <dd>
            AI systems that listen to patient encounters and automatically generate
            clinical documentation. Products like DAX Copilot, Abridge, and Freed
            transcribe conversations and draft notes in EHR format. Aims to reduce
            documentation burden and restore face-to-face patient time.
            <a href="ambient-ai.html">See our module on ambient AI tools.</a>
          </dd>
        </div>

        <div class="glossary-item">
          <dt>CDS (Clinical Decision Support)</dt>
          <dd>
            AI systems that provide diagnostic suggestions, treatment recommendations,
            or alerts based on patient data. Ranges from simple rule-based alerts to
            AI-powered tools like UpToDate, OpenEvidence, and Glass Health that synthesize
            evidence for specific clinical questions.
            <a href="clinical-decision-support.html">See our CDS module.</a>
          </dd>
        </div>

        <div class="glossary-item">
          <dt>FDA Clearance (510(k) / De Novo)</dt>
          <dd>
            The regulatory pathway for medical AI devices in the US. <strong>510(k)</strong>
            clearance means the device is "substantially equivalent" to an existing approved
            device. <strong>De Novo</strong> is for novel low-to-moderate risk devices.
            <strong>PMA</strong> (Premarket Approval) is for high-risk devices. Over 900
            AI/ML medical devices have received FDA clearance as of 2025.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>CDSS (Clinical Decision Support System)</dt>
          <dd>
            The broader category of software providing clinician-facing decision support.
            Includes both AI-powered and traditional rule-based systems. Often integrated
            into EHRs with alerts, order sets, and diagnostic suggestions.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>CADe / CADx</dt>
          <dd>
            <strong>CADe</strong> (Computer-Aided Detection): AI that identifies potential
            findings in medical images (e.g., flagging a possible nodule on chest CT).<br>
            <strong>CADx</strong> (Computer-Aided Diagnosis): AI that characterizes findings
            (e.g., suggesting a nodule is likely malignant). Radiology and pathology have
            the most FDA-cleared CAD tools.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>LLM-as-Judge</dt>
          <dd>
            Using one AI model to evaluate outputs from another—increasingly common in
            medical AI evaluation. Instead of only human review, an LLM assesses whether
            AI-generated clinical content is accurate, complete, and appropriate.
            Useful for scaling quality assessment but requires validation.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>Medical LLMs</dt>
          <dd>
            Language models fine-tuned or designed specifically for healthcare applications.
            Examples include Med-PaLM (Google), BioMistral, and various clinical GPT variants.
            Often trained on medical literature and clinical notes to improve healthcare-specific
            performance over general-purpose models.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>De-identification</dt>
          <dd>
            Removing or obscuring protected health information (PHI) from data before
            AI processing. HIPAA defines 18 identifiers that must be addressed. AI tools
            can help automate de-identification, but verification remains important.
            <a href="phi-hipaa.html">See our PHI and HIPAA module.</a>
          </dd>
        </div>

        <div class="glossary-item">
          <dt>BAA (Business Associate Agreement)</dt>
          <dd>
            Legal agreement required under HIPAA when sharing PHI with third parties,
            including AI vendors. A BAA establishes the vendor's obligations to protect
            health data. Using AI tools for patient data without a BAA violates HIPAA.
            Check whether your AI tools have BAA options.
          </dd>
        </div>

        <div class="glossary-item">
          <dt>Algorithmic Bias in Healthcare</dt>
          <dd>
            When AI systems produce systematically different (often worse) outcomes for
            certain patient populations. Can arise from training data that underrepresents
            groups, features that correlate with race/ethnicity, or historical disparities
            embedded in the data. A significant concern for healthcare AI equity.
          </dd>
        </div>
      </dl>

      <hr>

      <!-- Learning Resources -->
      <h2 id="resources">Multi-Modal Learning Resources</h2>

      <h3>Online Courses</h3>

      <div class="resource-list">
        <div class="resource-item">
          <h4>DeepLearning.AI: ChatGPT Prompt Engineering for Developers</h4>
          <span class="resource-badge free">Free</span>
          <p>
            Taught by Andrew Ng and OpenAI's Isa Fulford. The gold-standard
            introduction—1.5 hours covering LLM fundamentals, prompting best
            practices, and practical applications. Hands-on Jupyter notebooks
            included. Appropriate for anyone with basic Python familiarity,
            but useful insights for non-coders too.
          </p>
          <a href="https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/" target="_blank" rel="noopener">
            deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers
          </a>
        </div>

        <div class="resource-item">
          <h4>Google Prompting Essentials</h4>
          <span class="resource-badge free">Free</span>
          <p>
            Google's structured 5-step prompting framework. Covers multimodal
            prompting, prompt chaining, and building reusable prompt libraries.
            Under 6 hours. No technical background required—designed for practical
            workplace application.
          </p>
          <a href="https://grow.google/prompting-essentials/" target="_blank" rel="noopener">
            grow.google/prompting-essentials
          </a>
        </div>

        <div class="resource-item">
          <h4>IBM: Generative AI - Prompt Engineering Basics</h4>
          <span class="resource-badge free">Audit Free (Coursera)</span>
          <p>
            Solid overview from IBM covering zero-shot, few-shot, and chain-of-thought
            techniques. Includes hands-on labs and graded assessments. Good for those
            wanting a certificate to demonstrate competency.
          </p>
          <a href="https://www.coursera.org/learn/generative-ai-prompt-engineering-for-everyone" target="_blank" rel="noopener">
            coursera.org/learn/generative-ai-prompt-engineering-for-everyone
          </a>
        </div>

        <div class="resource-item">
          <h4>Learn Prompting: ChatGPT for Everyone</h4>
          <span class="resource-badge free">Free</span>
          <p>
            Open-source guide created in collaboration with OpenAI. Comprehensive
            and research-backed. Covers basics through advanced techniques. Over
            3 million learners. The written documentation is excellent for reference.
          </p>
          <a href="https://learnprompting.org/" target="_blank" rel="noopener">
            learnprompting.org
          </a>
        </div>

        <div class="resource-item">
          <h4>Udemy: Complete Prompt Engineering for AI Bootcamp</h4>
          <span class="resource-badge paid">Paid</span>
          <p>
            More comprehensive paid option covering GPT models, image generation
            (Midjourney, DALL-E), and coding assistants. Regularly updated. Good
            if you want one exhaustive resource.
          </p>
        </div>
      </div>

      <h3>Podcasts</h3>

      <div class="resource-list">
        <div class="resource-item">
          <h4>Practical AI (Changelog)</h4>
          <p>
            Weekly discussions on AI applications in the real world. Hosted by
            Daniel Whitenack and Chris Benson. Balances technical depth with
            accessibility. Good for staying current on practical developments.
          </p>
        </div>

        <div class="resource-item">
          <h4>TWIML AI Podcast (This Week in Machine Learning & AI)</h4>
          <p>
            Hosted by Sam Charrington. In-depth interviews with AI researchers
            and practitioners. More technical but explained well. Strong back
            catalog for topic-specific deep dives.
          </p>
        </div>

        <div class="resource-item">
          <h4>The AI Podcast (NVIDIA)</h4>
          <p>
            Bi-weekly episodes featuring AI innovators across industries—healthcare,
            climate, entertainment. Production quality is high. Good for understanding
            AI applications beyond pure tech.
          </p>
        </div>

        <div class="resource-item">
          <h4>Latent Space</h4>
          <p>
            Aimed at AI engineers and builders. Hosts Alessio Fanelli and Swyx
            cover latest developments, new research, and practical implementation.
            More technical but current and well-informed.
          </p>
        </div>

        <div class="resource-item">
          <h4>Cognitive Revolution</h4>
          <p>
            Hosted by Nathan Labenz. Focus on transformative potential of AI—interviews
            with researchers, founders, and investors. Good for understanding where
            the field is heading.
          </p>
        </div>

        <div class="resource-item">
          <h4>Hard Fork (New York Times)</h4>
          <p>
            Not AI-specific but covers AI developments extensively. Kevin Roose
            and Casey Newton offer accessible, journalist-perspective coverage
            of tech and AI news. Good for staying broadly informed.
          </p>
        </div>

        <div class="resource-item">
          <h4>DeepMind: The Podcast</h4>
          <p>
            Hosted by mathematician Hannah Fry. Explores AI research and its
            implications. Award-winning production. Less frequent but high quality.
            Good for deeper conceptual understanding.
          </p>
        </div>
      </div>

      <h3>YouTube Channels and Videos</h3>

      <div class="resource-list">
        <div class="resource-item">
          <h4>freeCodeCamp: Learn Prompt Engineering – Full Course</h4>
          <p>
            Ania Kubow's comprehensive crash course covering fundamentals through
            advanced techniques. Free, thorough, beginner-friendly. Good for visual
            learners who want structured progression.
          </p>
        </div>

        <div class="resource-item">
          <h4>DeepLearning.AI YouTube Channel</h4>
          <p>
            Andrew Ng's organization posts short course previews and standalone
            AI education content. Authoritative and well-produced.
          </p>
        </div>

        <div class="resource-item">
          <h4>AI Explained</h4>
          <p>
            Thoughtful analysis of AI developments, model comparisons, and capability
            assessments. Good for understanding what new releases actually mean
            rather than hype cycles.
          </p>
        </div>

        <div class="resource-item">
          <h4>Two Minute Papers</h4>
          <p>
            Karoly Zsolnai-Feher summarizes AI research papers in accessible,
            engaging videos. Good for keeping up with research developments
            without reading papers directly.
          </p>
        </div>
      </div>

      <h3>Reading and Reference</h3>

      <div class="resource-list">
        <div class="resource-item">
          <h4>Prompt Engineering Guide (DAIR.AI)</h4>
          <p>
            Open-source comprehensive guide with 3+ million users. Covers techniques,
            applications, and research papers. Constantly updated. The definitive
            written reference.
          </p>
          <a href="https://www.promptingguide.ai/" target="_blank" rel="noopener">
            promptingguide.ai
          </a>
        </div>

        <div class="resource-item">
          <h4>OpenAI's Prompt Engineering Guide</h4>
          <p>
            Direct from OpenAI—best practices for their models specifically.
            Authoritative for GPT usage patterns.
          </p>
        </div>

        <div class="resource-item">
          <h4>Anthropic's Prompt Engineering Documentation</h4>
          <p>
            Claude-specific guidance from Anthropic. Detailed best practices
            for Claude's particular strengths and patterns.
          </p>
          <a href="https://docs.anthropic.com/" target="_blank" rel="noopener">
            docs.anthropic.com
          </a>
        </div>

        <div class="resource-item">
          <h4>IBM Think: The 2025 Guide to Prompt Engineering</h4>
          <p>
            Comprehensive enterprise-oriented guide with practical frameworks
            and examples.
          </p>
          <a href="https://www.ibm.com/think/prompt-engineering" target="_blank" rel="noopener">
            ibm.com/think/prompt-engineering
          </a>
        </div>
      </div>

      <h3>Practice Environments</h3>

      <div class="concepts-grid">
        <div class="concept-card">
          <div class="concept-name">ChatGPT (OpenAI)</div>
          <div class="concept-desc">Most widely used interface. Free tier available.</div>
        </div>
        <div class="concept-card">
          <div class="concept-name">Claude (Anthropic)</div>
          <div class="concept-desc">Strong for long documents, analysis, and coding.</div>
        </div>
        <div class="concept-card">
          <div class="concept-name">Google AI Studio</div>
          <div class="concept-desc">Access to Gemini models with generous free tier.</div>
        </div>
        <div class="concept-card">
          <div class="concept-name">Hugging Face</div>
          <div class="concept-desc">Open-source model library with free inference API.</div>
        </div>
      </div>

      <h3>How to Use These Resources</h3>

      <div class="callout callout-info">
        <div class="callout-title">Time-Based Recommendations</div>
        <ul class="mb-0">
          <li><strong>15 minutes:</strong> Read the foundational sections of Learn Prompting or scan OpenAI's prompt engineering guide.</li>
          <li><strong>2 hours:</strong> Complete DeepLearning.AI's ChatGPT Prompt Engineering course.</li>
          <li><strong>A week:</strong> Work through Google Prompting Essentials, supplement with podcast episodes during commutes.</li>
          <li><strong>Building AI applications:</strong> DAIR.AI's Prompt Engineering Guide plus the technical documentation from your chosen model provider.</li>
          <li><strong>Ongoing learning:</strong> Subscribe to 2-3 podcasts and follow AI Explained on YouTube. The field moves fast—regular touchpoints prevent knowledge decay.</li>
        </ul>
      </div>

      <p class="text-muted text-small">
        <em>Last updated: November 2025. AI terminology evolves rapidly—new terms
        emerge and meanings shift. When in doubt, check primary sources from model providers.</em>
      </p>

      <!-- Page Navigation -->
      <nav class="page-nav">
        <a href="local-models.html" class="page-nav-link prev">
          <span class="page-nav-arrow"><i data-lucide="arrow-left"></i></span>
          <div>
            <span class="page-nav-label">Previous</span>
            <span class="page-nav-title">Running AI Models on Your Own Computer</span>
          </div>
        </a>
        <a href="index.html" class="page-nav-link next">
          <span class="page-nav-arrow"><i data-lucide="arrow-right"></i></span>
          <div>
            <span class="page-nav-label">Return to</span>
            <span class="page-nav-title">All Topics</span>
          </div>
        </a>
      </nav>

    </article>
  </main>

  <footer class="footer">
    <div class="footer-inner">
      <div><strong>AI 101</strong> · A Self-Paced Guide to AI in Medicine</div>
      <div>v1.0 · 2025</div>
    </div>
  </footer>

  <script>
    lucide.createIcons();
    const navToggle = document.querySelector('.nav-toggle');
    const navLinks = document.querySelector('.nav-links');
    if (navToggle) {
      navToggle.addEventListener('click', () => {
        navLinks.classList.toggle('nav-open');
      });
    }
  </script>

  <script src="https://studio.pickaxe.co/api/embed/bundle.js" defer></script>

</body>
</html>
