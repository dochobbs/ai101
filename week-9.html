<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Week 9: Module 16: Liability and Malpractice | AI 101</title>
  <link rel="stylesheet" href="styles.css">
  <script src="https://unpkg.com/lucide@latest"></script>
</head>
<body>

  <nav class="nav">
    <div class="nav-inner">
      <a href="index.html" class="nav-brand">
        <span class="nav-badge">AI 101</span>
        <span class="nav-title">A Self-Paced Guide to AI in Medicine</span>
      </a>
      <button class="nav-toggle" aria-label="Toggle menu">
        <i data-lucide="menu"></i>
      </button>
      <div class="nav-links">
        <a href="index.html" class="nav-link">Modules</a>
        <!-- <a href="resources.html" class="nav-link">Resources</a> -->
        <a href="about.html" class="nav-link">About</a>
      </div>
    </div>
  </nav>

  <main class="main">
    <article class="content">

      <header class="unit-header">
        <span class="unit-label phase-3">PHASE III 路 MODULE 16</span>
        <h1 class="unit-title">Liability and Malpractice</h1>
        <p class="unit-subtitle">
          Medical negligence vs. product liability, documentation standards,
          and the evolving legal landscape for clinical AI.
        </p>
        <div class="unit-meta">
          <span class="unit-meta-item">
            <i data-lucide="book-open"></i>
            4 readings
          </span>
        </div>
      </header>

      <div class="callout callout-question">
        <div class="callout-title">Core Question</div>
        <p class="mb-0">
          When an AI-assisted clinical decision leads to patient harm, who is 
          legally responsibleand how should clinicians protect themselves?
        </p>
      </div>

      <h2>Overview</h2>
      <p>
        Phase III shifts from technical to institutional concerns. Clinical AI 
        exists within legal frameworks designed for a pre-AI world, creating 
        uncertainty about liability when things go wrong. This week examines 
        the legal landscapenot to make you a lawyer, but to help you understand 
        the risk environment and document your AI use appropriately.
      </p>

      <h2>Key Concepts</h2>

      <h3>Two Liability Frameworks</h3>
      <p>
        AI-related harm could be addressed through two different legal theories:
      </p>
      <ul>
        <li>
          <strong>Medical malpractice:</strong> The traditional framework where 
          clinicians are liable for failing to meet the standard of care. If you 
          used AI and deviated from what a reasonable physician would do, you 
          might be liable regardless of whether the AI was at fault.
        </li>
        <li>
          <strong>Product liability:</strong> The manufacturer could be liable 
          if the AI itself was defective. But FDA-cleared devices often have 
          liability protections, and proving an algorithm was "defective" is 
          technically and legally complex.
        </li>
      </ul>
      <p>
        In practice, clinicians are the most accessible defendants. Even if the 
        AI vendor shares responsibility, you may bear the initial legal burden.
      </p>

      <h3>The Standard of Care Problem</h3>
      <p>
        Malpractice liability hinges on the "standard of care"what a reasonable 
        practitioner would do. But what's "reasonable" when AI is involved? 
        Should you be required to use available AI tools? Can you be liable for 
        ignoring an AI recommendation that turned out to be correct? These 
        questions are largely unresolved.
      </p>
      <p>
        The safest assumption: you remain responsible for clinical decisions 
        regardless of AI involvement. AI is a tool you use, not an entity that 
        shares your professional obligations.
      </p>

      <h3>Documentation for AI-Assisted Decisions</h3>
      <p>
        If your AI use ever comes under legal scrutiny, documentation will be 
        critical. Best practices include:
      </p>
      <ul>
        <li>Document which AI tools were used and for what purpose</li>
        <li>Note when you followed or deviated from AI recommendations, and why</li>
        <li>Record the information the AI had access to (it may not have seen everything you knew)</li>
        <li>Preserve AI outputs when possible, as these may be relevant to later review</li>
      </ul>

      <div class="callout callout-warning">
        <div class="callout-title">Legal Disclaimer</div>
        <p class="mb-0">
          This material is educational, not legal advice. Consult your 
          institution's legal counsel and risk management for guidance specific 
          to your practice setting and jurisdiction.
        </p>
      </div>

      <h2>Readings</h2>
      <div class="reading-list">
        <div class="reading-item">
          <div class="reading-type"></div>
          <div class="reading-content">
            <div class="reading-title">
              Price, W.N. et al. "Potential Liability for Physicians Using Artificial Intelligence"

            </div>
            <div class="reading-meta">JAMA, 2019 路 Foundational legal analysis</div>
          </div>
        </div>
        <div class="reading-item">
          <div class="reading-type"></div>
          <div class="reading-content">
            <div class="reading-title">
              Cohen, I.G. et al. "The Legal and Ethical Concerns That Arise from Using Complex Predictive Analytics in Health Care"

            </div>
            <div class="reading-meta">Health Affairs, 2014</div>
          </div>
        </div>
        <div class="reading-item">
          <div class="reading-type"></div>
          <div class="reading-content">
            <div class="reading-title">
              Mello, M. & Guha, N. "Understanding Liability Risk from Using Health Care Artificial Intelligence Tools"

            </div>
            <div class="reading-meta">NEJM, 2024 路 Updated legal landscape</div>
          </div>
        </div>
        <div class="reading-item">
          <div class="reading-type"></div>
          <div class="reading-content">
            <div class="reading-title">
              AMA. "Augmented Intelligence in Health Care" (policy statement)

            </div>
            <div class="reading-meta">Professional guidance document</div>
          </div>
        </div>
      </div>

      <div class="discussion-questions">
        <h4>Discussion Questions</h4>
        <ol>
          <li>
            An AI flagged a finding you dismissed, and the patient was later 
            harmed. How might this play out in a malpractice case? What 
            documentation would help your defense?
          </li>
          <li>
            Your hospital requires use of an AI sepsis alert system. You 
            disagree with an alert and don't act on it. What are your options 
            and their implications?
          </li>
          <li>
            Should AI vendors share malpractice liability with clinicians? 
            What are arguments for and against?
          </li>
        </ol>
      </div>

      <div class="objectives phase-3">
        <h4 class="objectives-title">Learning Objectives</h4>
        <ul class="objectives-list">
          <li>Distinguish between malpractice and product liability frameworks for AI harms</li>
          <li>Explain how standard of care applies to AI-assisted decisions</li>
          <li>Implement documentation practices that protect against liability exposure</li>
          <li>Identify unresolved legal questions in clinical AI</li>
        </ul>
      </div>

      <nav class="page-nav">
        <a href="bonus-vibe-coding.html" class="page-nav-link prev">
          <span class="page-nav-arrow"><i data-lucide="arrow-left"></i></span>
          <div>
            <span class="page-nav-label">Previous</span>
            <span class="page-nav-title">Bonus Module: Vibe Coding</span>
          </div>
        </a>
        <a href="week-10.html" class="page-nav-link next">
          <span class="page-nav-arrow"><i data-lucide="arrow-right"></i></span>
          <div>
            <span class="page-nav-label">Next</span>
            <span class="page-nav-title">Module 17: Institutional Governance</span>
          </div>
        </a>
      </nav>

    </article>
  </main>

  <footer class="footer">
    <div class="footer-inner">
      <div><strong>AI 101</strong> 路 A Self-Paced Guide to AI in Medicine</div>
      <div>v1.1 路 2025</div>
    </div>
  </footer>

  <script>
    lucide.createIcons();
    const navToggle = document.querySelector('.nav-toggle');
    const navLinks = document.querySelector('.nav-links');
    if (navToggle) {
      navToggle.addEventListener('click', () => {
        navLinks.classList.toggle('nav-open');
      });
    }
  </script>

  <script src="https://studio.pickaxe.co/api/embed/bundle.js" defer></script>

</body>
</html>
