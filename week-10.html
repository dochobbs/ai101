<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Week 10: Module 17: Institutional Governance | AI 101</title>
  <link rel="stylesheet" href="styles.css">
  <script src="https://unpkg.com/lucide@latest"></script>
</head>
<body>

  <nav class="nav">
    <div class="nav-inner">
      <a href="index.html" class="nav-brand">
        <span class="nav-badge">AI 101</span>
        <span class="nav-title">A Self-Paced Guide to AI in Medicine</span>
      </a>
      <button class="nav-toggle" aria-label="Toggle menu">
        <i data-lucide="menu"></i>
      </button>
      <div class="nav-links">
        <a href="index.html" class="nav-link">Modules</a>
        <!-- <a href="resources.html" class="nav-link">Resources</a> -->
        <a href="about.html" class="nav-link">About</a>
      </div>
    </div>
  </nav>

  <main class="main">
    <article class="content">

      <header class="unit-header">
        <span class="unit-label phase-3">PHASE III 路 MODULE 17</span>
        <h1 class="unit-title">Institutional Governance</h1>
        <p class="unit-subtitle">
          CONSORT-AI guidelines, AMA principles, shadow AI risks, and
          building governance infrastructure.
        </p>
        <div class="unit-meta">
          <span class="unit-meta-item">
            <i data-lucide="book-open"></i>
            5 readings
          </span>
        </div>
      </header>

      <div class="callout callout-question">
        <div class="callout-title">Core Question</div>
        <p class="mb-0">
          How should healthcare institutions evaluate, procure, deploy, and 
          monitor AI systemsand what happens when clinicians bring their 
          own tools?
        </p>
      </div>

      <h2>Overview</h2>
      <p>
        Individual clinician competence isn't enough. AI in healthcare requires 
        institutional infrastructure: governance committees, procurement 
        criteria, monitoring systems, and policies that define appropriate use. 
        This week examines frameworks for organizational AI governance and 
        confronts the challenge of "shadow AI"clinicians using consumer tools 
        outside institutional oversight.
      </p>

      <h2>Key Concepts</h2>

      <h3>Reporting Standards: CONSORT-AI and SPIRIT-AI</h3>
      <p>
        Just as clinical trials have CONSORT guidelines for transparent reporting, 
        AI interventions now have extensions: <strong>CONSORT-AI</strong> for 
        trial reports and <strong>SPIRIT-AI</strong> for protocols. These 
        standards specify what information must be disclosed about AI systems 
        used in clinical researchtraining data, validation, input/output 
        specifications, human oversight procedures.
      </p>
      <p>
        Governance committees can use these frameworks when evaluating AI 
        tools for institutional adoption, even outside research contexts.
      </p>

      <h3>AMA Principles for Augmented Intelligence</h3>
      <p>
        The AMA's framework emphasizes:
      </p>
      <ul>
        <li><strong>Transparency:</strong> Clinicians should understand what data AI uses and how it reaches conclusions</li>
        <li><strong>Human oversight:</strong> AI should support, not replace, clinical decision-making</li>
        <li><strong>Equity:</strong> AI deployment should be evaluated for bias and disparate impact</li>
        <li><strong>Accountability:</strong> Clear responsibility for AI-related decisions and outcomes</li>
      </ul>

      <h3>The Shadow AI Problem</h3>
      <p>
        While institutions deliberate, clinicians are already using ChatGPT on 
        personal devices, uploading clinical scenarios to consumer AI tools, 
        and adopting workarounds that bypass formal approval. This creates risks:
      </p>
      <ul>
        <li>PHI exposure to non-HIPAA-compliant services</li>
        <li>No institutional oversight of AI quality</li>
        <li>Liability ambiguity when things go wrong</li>
        <li>Inequitable access (some clinicians using AI, others not)</li>
      </ul>
      <p>
        Prohibition rarely works. Effective governance provides sanctioned 
        alternatives that meet clinicians' legitimate needs while maintaining 
        institutional oversight.
      </p>

      <h3>Building AI Governance Infrastructure</h3>
      <p>
        Components of mature AI governance:
      </p>
      <ul>
        <li><strong>AI Committee:</strong> Cross-functional body reviewing AI proposals (clinical, IT, legal, ethics, quality)</li>
        <li><strong>Procurement Criteria:</strong> Standardized evaluation framework for AI vendors</li>
        <li><strong>Monitoring Systems:</strong> Ongoing performance tracking, not just pre-deployment validation</li>
        <li><strong>Incident Reporting:</strong> Mechanisms for clinicians to report AI errors or concerns</li>
        <li><strong>Training Requirements:</strong> Competency standards for clinicians using AI tools</li>
      </ul>

      <div class="callout callout-info">
        <div class="callout-title">Activity: Governance Policy Draft</div>
        <p class="mb-0">
          Working in clinical squads, you'll draft an AI use policy for a 
          hypothetical hospital department. What should be allowed? Prohibited? 
          Required? What oversight mechanisms would you implement?
        </p>
      </div>

      <h2>Readings</h2>
      <div class="reading-list">
        <div class="reading-item">
          <div class="reading-type"></div>
          <div class="reading-content">
            <div class="reading-title">
              Liu, X. et al. "Reporting guidelines for clinical trial reports for interventions involving artificial intelligence: the CONSORT-AI extension"

            </div>
            <div class="reading-meta">Lancet Digital Health, 2020</div>
          </div>
        </div>
        <div class="reading-item">
          <div class="reading-type"></div>
          <div class="reading-content">
            <div class="reading-title">
              AMA. "Augmented Intelligence in Health Care"

            </div>
            <div class="reading-meta">Policy H-480.940 路 Full principles document</div>
          </div>
        </div>
        <div class="reading-item">
          <div class="reading-type"></div>
          <div class="reading-content">
            <div class="reading-title">
              Reddy, S. et al. "A governance model for the application of AI in health care"

            </div>
            <div class="reading-meta">JAMIA, 2020</div>
          </div>
        </div>
        <div class="reading-item">
          <div class="reading-type"></div>
          <div class="reading-content">
            <div class="reading-title">
              Gerke, S. et al. "The need for a system view to regulate artificial intelligence/machine learning-based software as medical device"

            </div>
            <div class="reading-meta">NPJ Digital Medicine, 2020</div>
          </div>
        </div>
      </div>

      <div class="discussion-questions">
        <h4>Discussion Questions</h4>
        <ol>
          <li>
            Your institution has no formal AI governance. A colleague asks 
            whether they can use GPT-4 to help with documentation. What do 
            you advise?
          </li>
          <li>
            How should an AI committee balance speed (clinicians want tools now) 
            with thoroughness (proper vetting takes time)?
          </li>
          <li>
            A vendor offers an FDA-cleared AI diagnostic tool but won't 
            disclose the training data due to "proprietary concerns." 
            Should your institution adopt it?
          </li>
        </ol>
      </div>

      <div class="objectives phase-3">
        <h4 class="objectives-title">Learning Objectives</h4>
        <ul class="objectives-list">
          <li>Apply CONSORT-AI criteria to evaluate AI intervention reports</li>
          <li>Articulate the AMA's principles for augmented intelligence</li>
          <li>Identify shadow AI risks and governance strategies to address them</li>
          <li>Design components of an institutional AI governance framework</li>
        </ul>
      </div>

      <nav class="page-nav">
        <a href="week-9.html" class="page-nav-link prev">
          <span class="page-nav-arrow"><i data-lucide="arrow-left"></i></span>
          <div>
            <span class="page-nav-label">Previous</span>
            <span class="page-nav-title">Module 16: Liability and Malpractice</span>
          </div>
        </a>
        <a href="week-11.html" class="page-nav-link next">
          <span class="page-nav-arrow"><i data-lucide="arrow-right"></i></span>
          <div>
            <span class="page-nav-label">Next</span>
            <span class="page-nav-title">Module 18: Patient Communication</span>
          </div>
        </a>
      </nav>

    </article>
  </main>

  <footer class="footer">
    <div class="footer-inner">
      <div><strong>AI 101</strong> 路 A Self-Paced Guide to AI in Medicine</div>
      <div>v1.0 路 2025</div>
    </div>
  </footer>

  <script>
    lucide.createIcons();
    const navToggle = document.querySelector('.nav-toggle');
    const navLinks = document.querySelector('.nav-links');
    if (navToggle) {
      navToggle.addEventListener('click', () => {
        navLinks.classList.toggle('nav-open');
      });
    }
  </script>

</body>
</html>
